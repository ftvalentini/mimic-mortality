---
lang: es
fontsize: 12pt
output:
  bookdown::pdf_document2:
    fig_caption: true
    toc: true
    number_sections: true
abstract: |
  El presente trabajo hace un análisis no supervisado y supervisado de pacientes de la Unidad de Terapia Intensiva del Beth Israel Deaconess Medical Center de Boston ingresados entre 2001 y 2012, usando la información recopilada durante el primer día de internación. En primer lugar, se desarrolla un indicador de casos atípicos implementando las técnicas de Kurtosis plus Specific Directions y de Redes Neuronales Autoencoders. En segundo lugar, se genera un predictor de mortalidad durante la primera semana ajustando un Modelo Aditivo Generalizado (GAM) con regularización. Por último, se evalúa la capacidad predictiva del indicador de atipicidad y del predictor GAM frente a tres scores de severidad estándar en unidades de terapia intensiva.   
bibliography: ["biblio.bib"]
link-citations: yes
# linkcolor: blue (NO FUNCIONA!!!)
biblio-style: apalike
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F, warning=F, message=F, fig.align='center')
# knitr::opts_chunk$set(fig.path = "../output/plots/")
knitr::opts_knit$set(root.dir=normalizePath('../'))
library(knitr)
library(kableExtra)
```

```{r libfunc}
source("functions.R")
library(keras)
library(dplyr)
```

\newpage

# Introducción

El presente trabajo se propone hacer un análisis no supervisado y supervisado de pacientes de la Unidad de Terapia Intensiva del Beth Israel Deaconess Medical Center de Boston ingresados entre 2001 y 2012.

En lo que refiere al aprendizaje no supervisado, generamos un indicador de atipicidad o anomalía de los pacientes en términos de las mediciones fisiológicas y características físicas registradas durante las primeras 24 horas después de su ingreso. En particular, ajustamos dos indicadores usando las técnicas de *Kurtosis plus Specific Directions* [@ksd] y de Autoencoder [@autoencoder1]. Estos indicadores podrían usarse en la práctica como insumo para tratar pacientes así como también para el desarrollo de investigaciones. 

En cuanto al aprendizaje supervisado, generamos un predictor de mortalidad dentro de los 7 días posteriores a la internación usando como insumo los atributos de las primeras 24 horas usados para la tarea no supervisada. En particular, ajustamos un Modelo Aditivo Generalizado con penalización de tipo *lasso* [@gamsel]. La elección del modelo se debe a que permite captar no linealidaes y alcanzar mejor precisión en la clasificación que modelos más simples, a la vez que admite interpretar el impacto de los principales factores asociados a la mortalidad por separado, dada la aditividad del modelo. Asimismo, la regularización realiza selección automática de variables relevantes a la vez que trata la potencial multicolinealidad que trae aparejada el uso de atributos correlacionados. 

El predictor GAM es validado mediante *model stacking* (ver sección \@ref(meto-stacking)) en una regresión logística junto al indicador de anomalía ajustado con el Autoencoder, y junto a tres predictores estándar de severidad que también usan información de las primeras 24 horas: SOFA [@sofa], SAPSII [@sapsii] y OASIS [@oasis]. El objetivo de esta etapa es evaluar la significatividad del aporte de ambos indicadores --el predictor de mortalidad y el indicador de atipicidad-- a la predicción de mortalidad en la primera semana. 

# Materiales y métodos

## Fuentes de datos

El estudio se hizo con MIMIC-III, una base de libre acceso con datos anonimizados de pacientes internados en la Unidad de Terapia Intensiva (UTI) del Beth Israel Deaconess Medical Center de Boston entre 2001 y 2012 [@mimic].

MIMIC-III incluye datos demográficos, mediciones horarias de signos vitales, resultados de pruebas de laboratorio, procedimientos, medicamentos, notas de cuidadores, informes de imágenes y eventos relevantes tanto dentro como fuera del hospital --por ejemplo, la mortalidad. Se puede acceder a una descripción del esquema completo de tablas en el [repositorio oficial del MIT Laboratory for Computational Physiology](https://mit-lcp.github.io/mimic-schema-spy/). Las operaciones de extracción y preprocesamiento de los datos se describen en la sección \@ref(prep).

## Algoritmos

### Imputación de datos faltantes

Para imputar valores numéricos faltantes durante la etapa de preprocesamiento (ver sección \@ref(prep-faltantes)) se usó el procedimiento de *median polish* de Tukey (ver @hoaglin).

La técnica parte del supuesto de que el valor $x_{ij}$ que toma cada registro $i$ para cada covariable $j$ se modela como un modelo lineal y aditivo
$x_{ij} = \mu + \alpha_{i} + \beta_{j} + \varepsilon_{ij}$,
tal que $\mu$ representa el "valor común" o efecto general del set de datos, $\alpha_{i}$ es el efecto por fila, $\beta_{j}$ es el efecto por columna y $\varepsilon_{ij}$ son fluctuaciones aleatorias.

El procedimiento de *median polish* consiste en estimar $\mu$, $\alpha_{i}$ y $\beta_{j}$ iterativamente, sustrayendo las medianas por fila y columna de los datos hasta que la mediana de los residuos se acerque a cero, dado un máximo de iteraciones prefijado. En lugar de un modelo de ANOVA para la estimación del modelo aditivo, elegimos *median polish* por su robustez a valores atípicos.

Considerando que el objetivo final no es inferir los parámetros del modelo, sino imputar valores de variables con distintas unidades de medidas, resumimos la técnica de imputación implementada de la siguiente manera:

1. Se estandarizan las columnas sustrayendo las medianas y diviendo por los desvíos absolutos medianos (MAD) de cada una, omitiendo los valores faltantes (si algún MAD equivale a cero, se sumaron pequeños desvíos en relación a la escala de la variable para computarlo).
2. Se estiman el efecto general y los efectos por fila y columna usando *median polish* omitiendo los valores faltantes.
3. Se imputan los valores faltantes de los datos normalizados sumando correspondientemente los efectos estimados en el paso anterior.
4. Se reescalan las variables a su escala original multiplcando por los MADs y sumando las medianas calculadas en el primer paso.

Esta técnica fue aplicada una vez descartadas las variables con una alta proporción de valores faltantes (ver sección \@ref(prep-faltantes)).

### Detección de anomalías {#meto-anom}

Para identificar casos anómalos nos propusimos generar indicadores de *outlyingness* que indiquen el grado de atipicidad o anomalía de cada observación. Los indicadores usan los predictores del set completo de internaciones ya preprocesado, sin incluir la variable respuesta de mortalidad del análisis supervisado. No es de interés en esta aplicación identificar puntos de corte en los indicadores que separen lo anómalo de lo no-anómalo.

Para la tarea de detección de anomalías, los algoritmos descritos en esta sección se ajustaron inicialmente sobre todo el set de datos y posteriormente se compararon visualmente. Sin embargo, como también era de interés analizar si el indicador ajustado con un autoencoder contribuye a la predicción de mortalidad, lo entrenamos en segunda instancia siguiendo un criterio acorde a una tarea supervisada, que se describe en la sección \@ref(meto-stacking).

#### Kurtosis plus Specific Directions (KSD)

La detección de observaciones atípicas en datos multivariados puede lograrse hallando una proyección univariada de los datos que indique el grado de atipicidad o *outlyingness* de cada uno: si una observación dada tiene un valor alto en esta proyección, entonces se clasifica como outlier multivariado.

De esta manera, sean $X$ la matriz de datos y $x$ una observación particular tal que $x \in R^{p}$, siendo $p$ la cantidad de atributos, el problema consiste en hallar una dirección $a$ tal que $||a|| = 1$ y tal que:

$$t(x) = \max_{a} \left|\frac{x'a - \hat{\mu}(a'X)}{\hat{\sigma}(a'X)}\right|$$

donde $\hat{\mu}$ y $\hat{\sigma}$ son estimadores robustos de posición y dispersión, respectivamente [@maronna].

El procedimiento de *Kurtosis plus Specific Directions* (KSD) propuesto por @ksd intenta hallar $a$ usando las dos siguientes observaciones:

1. Una pequeña proporción de valores atípicos tiende a incrementar la curtosis de una distribución --las colas se vuelven más pesadas-- mientras que una proporción alta disminuye la curtosis --la distribución se vuelve más bimodal.
2. Se puede aumentar la probabilidad de obtener direcciones buenas --que detecten valores atípicos-- mediante un mecanismo de muestreo estratificado.

Por lo tanto, el  método KSD busca iterativamente proyecciones que maximicen y minimicen la curtosis, así como también direcciones obtenidas al azar. Sobre estas direcciones se computa $t(x)$, que se usa en el presente trabajo como indicador de anomalía o atipicidad de una estadía en la UTI. Si bien el método descrito en @ksd posee un paso adicional para definir qué observaciones efectivamente son outliers --el cual recibe el nombre de "checking"--, en esta aplicación usamos la cantidad $t(x)$ directamente como indicador del grado de atipicidad y obviamos este paso.  

#### Autoencoder

Otro método posible para detectar anomalías consiste en ajustar un modelo que busque reconstruir las propias observaciones, de modo que aquellos casos con un error de reconstrucción alto --desvíos altos con respecto al modelo aprendido-- se puedan catalogar como *outliers*. 

Para este fin usamos la arquitectura de redes neuronales conocida como *autoencoder* (AE) (ver @autoencoder1 y @autoencoder2). Un AE consiste en una red neuronal con tantas neuronas como features en la capa de entrada y tantas neuronas como features en la capa de salida, y cuyos pesos se ajustan para intentar reproducir el input. 

En particular, los AE llamados *undercomplete* reducen la cantidad de neuronas en las capas intermedias en relación a las capas de entrada/salida, a fin de generar una representación en baja dimensión de los datos. Las salidas de las capas intermedias funcionan como un espacio latente o *embedding* que capturan las dimensiones más importantes de la distribución multivariada. Al reconstruir los datos desde esta representación latente se obtiene una reconstrucción de cada registro en la dimensión original, libre de ruido y anomalías. Entonces, el error de reconstrucción de una observación dada, que es el error entre el punto original y su reconstrucción, se usa como un indicador de *outlyingness*.

Formalmente, partiendo de una observación dada $x \in R^{p}$, el AE codifica $x$ con múltiples representaciones intermedias $x^{int} \in R^{k}$ tal que $k$ representa la cantidad de neuronas de una capa intermedia dada y tal que $k<p$. La representación de menor dimensión es luego decodificada como $\hat{x} \in R^{p}$ y se computa el score de *outlyingness* como $t(x) = Ave(x-\hat{x})^2$.

La estructura del AE implementado --sin considerar la capa de input-- se describe en la Figura \@ref(fig:auto-estructura). Usamos una red *feed-forward* y *fully-connected* con cinco capas intermedias (*latent1* hasta *latent5*) tal que los datos llegan a representarse en dos dimensiones en la capa *latent3*. Todas las capas intermedias usan funciones de activación ReLU mientras que la capa de salida usa activaciones lineales. Los pesos se entrenaron mediante el algoritmo de optimización Adam.    

```{r auto-estructura, out.width='90%', fig.cap="Estructura del autoencoder implementado"}
auto_mod = load_model_hdf5("data/working/model_autoencoder.h5",compile = FALSE)
print_output(summary(auto_mod), cex=0.75)
```

### Predicción de mortalidad

El objetivo de aprendizaje supervisado es la predicción de mortalidad durante los 7 días siguientes a la internación ($mor7$) --el evento de mortalidad se codifica como $mor7 = 1$ y la supervivencia como $mor7 = 0$. Para este fin se ajusta un Modelo Aditivo Generalizado regularizado (GAM) usando como covariables mediciones realizadas durante las primeras 24 horas de internación (ver Sección \@ref(prep-atr)). El predictor GAM es validado mediante *model stacking* en una regresión logística junto a otros predictores estándar de mortalidad y al indicador de anomalía *AE*, a fin de determinar la significatividad de su aporte a la predicción de *mor7*.  

Para realizar ambos ejercicios los registros fueron separados al azar entre un set de entrenamiento (85% de los datos) y un set de test (15% de los datos). 

#### Modelo Aditivo Generalizado (GAM) {#gam}

Los Modelos Aditivos Generalizados (GAMs) permiten modelar relaciones no lineales entre cada covariable $x_j$ y la respuesta $Y$ ajustando funciones suaves y no lineales $f_j(x_{j})$ para cada covariable por separado. En esta aplicación, en la medida en que el target es binario, ajustamos un GAM de regresión logística según la expresión:

$$ log\left(\frac{p(Y=1|X)}{1-p(Y=1|X)}\right) = \beta_0 + \sum_{j=1}^{p}f_{j}(x_{ij}) + \epsilon_i $$

según la cual el *logodds* de *mor7* es una función no lineal y aditiva de las covariables $x_j$. Transformando las *logodds* se puede obtener el resultado del modelo como una probabilidad de mortalidad estimada.

Para ajustar el modelo usamos la metodología presentada por @gamsel. La misma propone un enfoque de estimación penalizada que permite ajustar cada $f_j$ como cero, lineal o no lineal según lo sugerido por los datos. Gracias a este mecanismo de *feature selection* se pueden filtrar variables irrelevantes o redundantes automáticamente, ajustar funciones lineales cuando son una buena aproximación o capturar relaciones no lineales fuertes cuando están presentes. El parámetro que regula el grado de penalización es $\lambda$; para $\lambda=0$ se conservan todas las covariables en el modelo, mientras que para $\lambda \to \infty$ el efecto de todos los predictores tiende a cero. Todas las covariables se estandarizan con las medias y desvíos estimados con los datos de entrenamiento antes de realizar el ajuste.  

Debido al doble objetivo que perseguimos en el aprendizaje supervisado --entender el impacto de los principales factores asociados a la mortalidad (1) y optimizar la precisión en la predicción de mortalidad (2)-- ajustamos el GAM penalizado de las dos maneras siguientes:   

(1) Se usa un parámetro de regularización lo suficientemente alto como para identificar y visualizar el efecto de a lo sumo las 30 covariables más importantes, usando todos los datos de entrenamiento. Esta decisión tiene una justificación puramente de inferencia, dado que el $\lambda$ que optimiza la capacidad preditiva en sets de validación selecciona demasiadas variables con coeficiente no nulo, dificultando la interpretación.

(2) Para optimizar la capacidad predictiva se usa el valor del parámetro $\lambda$ que optimiza el *accuracy* a la hora de predecir nuevos casos. El valor de $\lambda$ se halla mediante 10-fold Cross-Validation usando los datos de entrenamiento. La performance final del predictor (*GAMpred*) se evalúa en el set de test.

#### Stacking {#meto-stacking}

Esta etapa consiste en ajustar una regresión logística usando como covariables
(1) el indicador de atipicidad *AE*, (2) el predictor *GAMpred* y (3) tres scores estándar de mortalidad que usan información de las primeras 24 horas de internación; y usando como variable respuesta *mor7*.

El indicador *AE* se ajusta con los datos de entrenamiento mientras que *GAMpred* se ajusta como se indicó en la Sección \@ref(gam). En base a estos modelos ajustados se extraen las predicciones sobre el set de test que se usan como covariables en el *stacked model*. La regresión logística se ajusta con los datos de test remuestrados en 500 sets de bootstrap. A partir de la evaluación de la significatividad media de los coeficientes de (1) y (2) en las regresiones de bootstrap se puede evaluar la contribución a la predicción de mortalidad.

Cabe destacar que para evaluar correctamente la capacidad predictiva de los dos modelos (*AE* y *GAMpred*) sería necesario incluir en la validación todos las etapas del proceso de modelado además de la estimación de la probabilidad: en particular, todas las decisiones de preprocesamiento de los datos descritas en la Sección \@ref(prep).

## Software usado

Para almacenar y preprocesar la base MIMIC-III usamos el motor de bases de datos PostgreSQL. Para todos los análisis restantes usamos el lenguaje R [@rbase], haciendo uso en particular de las librerías *tidyverse* [@rtidyverse], *gamsel* [@rgamsel] y *keras* [@rkeras].

# Preprocesamiento {#prep}

## Extracción de datos

De MIMIC-III conservamos atributos personales y mediciones fisiólogicas de cada paciente registrados en las primeras 24 horas de internación en la UTI médica --no se consideran pacientes de otros tipos de unidades (por ejemplo, neonatal o quirúrgica). Para cada paciente consideramos únicamente el primer ingreso al hospital y a la UTI, a la vez que eliminamos pacientes con transferencias entre unidades del hospital. La variable respuesta fue construida observando el evento de mortalidad en una ventana de 7 días posteriores a las primeras 24 horas de internación.  

Con la información disponible calculamos tres indicadores estándar de severidad que también usan la información de las primeras 24 horas: el *Sequential Organ Failure Assessment* SOFA [@sofa], el *Simplified Acute Physiology Score II* SAPS II [@sapsii] y el *Oxford Acute Severity of Illness Score* OASIS [@oasis].

Para generar las vistas y tablas necesarias para extraer los datos usamos el código disponible en @mimic-code.

## Generación de atributos {#prep-atr}

Como resultado de la extracción de atributos obtuvimos un set de covariables medidos una o más veces durante las primeras 24 horas, que se muestran en el Cuadro \@ref(tab:tab-vars). Aquellas covariables con más de una medición durante el primer día de internación se resumieron usando estadísticos de mínimo, máximo, media y coeficiente de tendencia con respecto al tiempo.

```{r tab-vars}
tab_vars = readr::read_csv("resources/var_definitions.csv")
knitr::kable(
  tab_vars
  # list(
  #   tab_vars %>% head(nrow(.)/3)
  #   ,tab_vars %>% slice((nrow(.)/3+1):(2*nrow(.)/3))
  #   ,tab_vars %>% tail(nrow(.)/3)
  # )
  ,caption="Mediciones durante las primeras 24 horas de internación", booktabs=T) %>%
  kable_styling(font_size=9)
```

## Tratamiento de datos faltantes {#prep-faltantes}

Eliminamos las variables con un porcentaje de faltantes mayor al 50%, y para completar los valores faltantes restantes aplicamos la técnica de *median polish*.

## Tratamiento de valores atípicos

```{r}
tabla = readRDS("data/working/x_train_auto.rds") %>% 
  rbind(readRDS("data/working/x_test_auto.rds"))
```

Durante el preprocesamiento eliminamos aquellos registros con mediciones afectadas seguramente por errores de carga --por ejemplo, pacientes con más de 120 años, con nitrógeno ureico en sangre negativo o con producción de orina superior a los 100 litros.  

Como resultado de las tareas de preprocesamiento descritas en la Sección \@ref(prep) generamos un set de datos listo para entrenar los algoritmos --previo al remuestreo-- conformado por `r ncol(tabla)` covariables y `r nrow(tabla)` registros.

# Modelado y resultados

## Detección de anomalías

```{r}
out_ksd = readRDS("data/working/outliers_full_ksd.rds")
out_auto = readRDS("data/working/outliers_full_auto.rds")
out = inner_join(out_ksd, out_auto, by="id_tot", suffix=c("_ksd","_auto"))
```

En la presente sección se presentan los resultados de aplicar los procedimientos de KSD y AE tal como se describe en la sección \@ref(meto-anom).

En la Figura \@ref(fig:auto-full) se presenta el detalle de la evolución del error cuadrático medio para cada *epoch* del entrenamiento del autoencoder. El error se estabiliza aproximadamente a partir de la recorrida nº 15 por el set de datos.

```{r auto-full, out.width='60%', fig.cap="Entrenamiento de autoencoder para detección de anomalías"}
auto_fit_full = readRDS("data/working/auto_fithistory_full.rds")
plot(auto_fit_full, metrics="loss")
```

Al comparar los indicadores de *outlyingness* AE y KSD en escala logarítmica se observa que ambos tienen una distribución asimétrica --lo cual es de esperar porque se tratan de indicadores de atipicidad; la asimetría es más marcada en el caso de KSD, lo cual sugiere que se pueden catalogar más pacientes como atípicos usando esta técnica (ver Figura \@ref(fig:auto-ksd)). Por otra parte, en el diagrama de dispersión se observa que los indicadores presentan un grado de asociación no despreciable, arrojando un coeficiente de correlación de Spearman --en la escala original-- de `r cor(out$out_ksd, out$out_auto, method="spearman") %>% round(2)`.

```{r auto-ksd, out.width='45%', fig.show='hold', fig.cap="Outlyingness KSD vs. autoencoder (escala logarítmica)"}
knitr::include_graphics(c(
  "../output/plots/outliers_scatter_logorig.png"
  ,"../output/plots/outliers_dens_log.png"
))
```

## Predicción de mortalidad

### Modelo Aditivo Generalizado (GAM)

#### Factores de riesgo de mortalidad

En la presente sección presentamos los resultados de entrenar un GAM con regularización persiguiendo un objetivo de inferencia --presentado como objetivo (1) en la sección \@ref(gam). Todas las covariables consideradas para entrenar el GAM según las transformaciones descritas en la sección \@ref(prep-atr) se indican en ell Cuadro \@ref(tab:gam-allvars).

```{r gam-allvars}
tab_vars = readRDS("output/tables/vars_reference.rds")
knitr::kable(
  list(
    tab_vars %>% head(nrow(.)/3)
    ,tab_vars %>% slice((nrow(.)/3+1):(2*nrow(.)/3))
    ,tab_vars %>% tail(nrow(.)/3)
  )
  ,caption="Predictores incluidos en GAM", booktabs=T) %>%
  kable_styling(font_size=8)
```

Para conservar no más de 30 de las covariables más relevantes en términos de capacidad predictiva escogimos un valor de $\lambda =$ 1.578 --el Cuadro \@ref(tab:gam-reg) indica la cantidad de predictores identificados por el GAM con un efecto no nulo sobre la probabilidad de mortalidad para cada posible valor de $\lambda$ en el *path* de penalización.    

```{r gam-reg}
gam_vars = readRDS("output/tables/gam_nonzero_lambda.rds")
tab = gam_vars %>% arrange(NonZero) %>% group_by(NonZero) %>%
  dplyr::filter(row_number()==1)
knitr::kable(
  list(
    tab %>% head(nrow(.)/2)
    ,tab %>% tail(nrow(.)/2)
  )
  ,caption="Cantidad de predictores en el regularization path del GAM", booktabs=T) %>%
  kable_styling(font_size=8)
```

En la Figura \@ref(fig:gam-vars) se representa visualmente el efecto *ceteris-paribus* estimado de cada covariable sobre el *log-odds* de la mortalidad --en verde se indican los efectos linales y en rojo, los no lineales. Las covariables de los ejes horizontales se presentan estandarizadas según las medias y varianzas del dataset de entrenamiento.

Se identifican únicamente cuatro efectos no lineales, que corresponden al potasio mínimo (v23), la frecuencia cardíaca (v37), la tendencia en el tiempo de la presión arterial media (v50) y la temperatura corporal media (v56). Las cuatro funciones estimadas tienen el mismo patrón: para valores relativemente altos y bajos de estos atributos la probabilidad de mortalidad estimada es más alta, mientras que baja para valores intermedios.  

En cuanto a la significatividad empírica del efecto, se destacan por su efecto negativo sobre la probabilidad de muerte las covariables de gasto urinario (v2), presión arterial sistólica media (v40) y saturación de oxígeno capilar periférica --media (v60) y con su coeficiente de tendencia (v61). Por su parte, el lactato mínimo (v19), el lactato máximo (v20), el tiempo de protrombina mínimo (v27), el mínimo conteo de glóbulos blancos (v35) y el crecimiento de la temperatura corporal en el tiempo (v57) presentan un efecto positivo significativo sobre la mortalidad --a medida que toman valores más altos entre los distintos pacientes crece la probabilidad estimada de muerte en la primera semana.  

```{r gam-vars, out.width='100%', fig.cap="Variables explicativas del GAM (lambda=1.578)"}
knitr::include_graphics("../output/plots/gam_vars.png")
```

#### Predicción

Para ajustar un GAM que optimice la capacidad predictiva --según el objetivo (2) planteado en la sección \@ref(gam)-- se escogió un valor del parámetro de penalización $\lambda$ tal que optimice el error de clasificación estimado por 10-fold Cross Validation. En particular, elegimos el modelo con mayor penalización ($\lambda$ más alto) tal que el error medio se encuentre a un desvío estándar del error medio mínimo --este valor se destaca en la barra vertical derecha de la Figura \@ref(fig:gam-cv). Como se observa en el eje horizontal superior, dicho valor implica un modelo que conserva 40 covariables con efectos no nulos sobre la probabilidad de muerte estimada.

```{r gam-cv, out.width='70%', fig.cap="Error de clasificación de 10-fold CV según penalización del GAM"}
knitr::include_graphics("../output/plots/gam_cv.png")
```

Para comparar la performance del modelo ajustado con los tres scores de severidad replicados --OASIS, SOFA y SAPSII-- graficamos la curva de ROC (Figura \@ref(fig:gam-roc)) y computamos el área debajo de la curva, *AUC* (Cuadro \@ref(tab:gam-auc)), a la vez que comparamos la distribución de la probabilidad estimada entre sobrevivientes y fallecidos durante la primera semana (Figura \@ref(fig:gam-violin)). Los tres resultados se obtuvieron calculando los indicadores a partir de los datos de test.

```{r gam-roc, out.width='60%', fig.cap="Curva de ROC: GAM y scores de severidad estándar"}
knitr::include_graphics("../output/plots/gam_roc.png")
```

```{r gam-auc}
tab_auc = readRDS("output/tables/gam_auroc.rds")
tab_auc %>%
  mutate_all(function(x) round(x*100,2)) %>%
  setNames(c("GAM","OASIS","SAPSII","SOFA")) %>%
  knitr::kable(caption="Área debajo de la curva ROC: GAM y scores de severidad estándar",booktabs=T) %>%
  kable_styling(font_size=10)
```

```{r gam-violin, out.width='90%', fig.cap="Distribución de positivos y negativos: GAM y scores de severidad estándar"}
knitr::include_graphics("../output/plots/gam_violin.png")
```

El predictor *GAMpred* desarrollado presenta una *AUC* superior a los scores estándar. Sin embargo cabe tener en cuenta las siguientes consideraciones a la hora de hacer la comparación:

(1) Si bien la *AUC* es mayor, la curva no se ubica consistentemente por encima de la curva del resto de los predictores --en particular, *GAMpred* se ve superado por OASIS y SAPSII en el primer tramo de la curva. 

(2) Los cuatro predictores tienen problemas de sensibilidad para cualquier punto de corte que se pueda plantear si fuera necesario clasificar: mientras que los casos negativos (no-mortalidad) se ajustan con una probabilidad baja exitosamente, los casos de mortalidad efectiva no logran estimarse en buena medida con una probabilidad alta, como se observa en la Figura \@ref(fig:gam-violin).

(3) Se cuenta con una sola estimación de *AUC* en test para cada indicador. La bondad de la comparación sería superior si se realizara más de una partición de remuestro en el set de datos, lo que permitiría evaluar el poder predictivo con la media de múltiples estimaciones de *AUC* para cada predictor.

(4) Para que la comparación sea válida sería necesario:
- Predecir mortalidad con *GAMpred* en pacientes de otros hospitales en otros momentos del tiempo, ya que los tres scores de severidad no fueron ajustados con datos del Beth Israel Deaconess Medical Center, mientras que *GAMpred*, sí.

- Incluir en la validación las etapas de preprocesamiento descritas en la sección \@ref(prep) --por ejemplo, la imputación de faltantes con *median polish* debería realizarse con los datos de test únicamente.

### Stacking

En la Figura \@ref(fig:stack-corplot) presentamos el correlograma de Pearson de las variables incluidas en la regresión logística *stacked* ajustada con los registros de test: el indicador de atipicidad *AE* en escala logarítmica (outl_auto_log), el predictor *GAMpred* (pred_gam) y los tres scores estándar de severidad (oasis, sapsii y sofa).

```{r stack-corplot, out.width='70%', fig.cap="Correlograma de los predictores en la regresión logística"}
knitr::include_graphics("../output/plots/stacked_corplot.png")
```

Ningún par de regresores presenta una correlación bivariada de Pearson que se pueda considerar como muy alta, lo cual indica que todos captan factores de mortalidad relativamente distintos y que podemos asumir la ausencia de colinealidad --al menos en un sentido bivariado-- en la regresión logística.

Con el fin de aumentar el grado de confianza en la inferencia que hacemos de la regresión estimada, ajustamos el modelo en 500 sets de bootstrap usando como base el set de test; computamos la media y el desvío de los coeficientes estimados, así como también el promedio de los p-valores. 

```{r stack-boot}
tab_stack = readRDS("output/tables/boot_stacked_logistic_test.rds")
tab_stack %>%
  mutate_if(is.numeric, function(x) round(x,5)) %>%
  knitr::kable(caption="Resultados de regresión logística (bootstrap de 500 repeticiones)",booktabs=T) %>%
  kable_styling(font_size=10)
```

Como se indica en el Cuadro \@ref(tab:stack-boot), *predGAM* es consistentemente el predictor con más importancia para la predicción de mortalidad, seguido por OASIS. Esto es razonable porque, si bien *predGAM* no fue ajustado con los datos de test, fue ajustado con datos del mismo hospital --de esta manera, es más que razonable que capte mejor las características del proceso generador de datos que los indicadores estándar.

Por su parte, el indicador de atipicidad AE no presenta un aporte significativo una vez que se consideran los predictores propios de mortalidad (*predGAM* y los tres scores estándar).  

# Referencias
